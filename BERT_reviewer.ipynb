{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb5bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#This code was modified from https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb#scrollTo=iCoyxRJ7ECTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc12035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# For DistilBERT:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "425a6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rest = pd.read_csv('Restaurant_Reviews.tsv', sep='\\t')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_rest['Review'], df_rest['Liked'], test_size=0.05, random_state=98)\n",
    "\n",
    "tokenized = df_rest['Review'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "        \n",
    "tokenized = X_train.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41c1d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a4bc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 43)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57bf9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07b245d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7138b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(Train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc10764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 43)\n"
     ]
    }
   ],
   "source": [
    "tokenized = X_test.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "print(padded.shape)\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape\n",
    "\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "Test_features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cfde5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(Test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8072f3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything was gross. 0[0]\n",
      "Thus far, have only visited twice and the food was absolutely delicious each time. 1[1]\n",
      "\u001b[91m This place has a lot of promise but fails to deliver. Unfavorable Review, Favorable Prediction (FP) 0[1]\u001b[00m\n",
      "I would avoid this place if you are staying in the Mirage. 0[0]\n",
      "The sangria was about half of a glass wine full and was $12, ridiculous. 0[0]\n",
      "Their frozen margaritas are WAY too sugary for my taste. 0[0]\n",
      "This place is not quality sushi, it is not a quality restaurant. 0[0]\n",
      "I had the opportunity today to sample your amazing pizzas! 1[1]\n",
      "The selection of food was not the best. 0[0]\n",
      "I've had better atmosphere. 0[0]\n",
      "Before I go in to why I gave a 1 star rating please know that this was my third time eating at Bachi burger before writing a review. 0[0]\n",
      "I took back my money and got outta there. 0[0]\n",
      "Anyways, The food was definitely not filling at all, and for the price you pay you should expect more. 0[0]\n",
      "Our server was super nice and checked on us many times. 1[1]\n",
      "\u001b[92m Plus, it's only 8 bucks. Favorable Review, Unfavorable Prediction (FN) 1[0]\u001b[00m\n",
      "Love the margaritas, too! 1[1]\n",
      "I came back today since they relocated and still not impressed. 0[0]\n",
      "\u001b[92m Nice blanket of moz over top but i feel like this was done to cover up the subpar food. Favorable Review, Unfavorable Prediction (FN) 1[0]\u001b[00m\n",
      "I have watched their prices inflate, portions get smaller and management attitudes grow rapidly! 0[0]\n",
      "The ambience is wonderful and there is music playing. 1[1]\n",
      "Today was my first taste of a Buldogis Gourmet Hot Dog and I have to tell you it was more than I ever thought possible. 1[1]\n",
      "The only thing I wasn't too crazy about was their guacamole as I don't like it pur√©ed. 0[0]\n",
      "Food was delicious! 1[1]\n",
      "The pizza tasted old, super chewy in not a good way. 0[0]\n",
      "It lacked flavor, seemed undercooked, and dry. 0[0]\n",
      "Restaurant is always full but never a wait. 1[1]\n",
      "They really want to make your experience a good one. 1[1]\n",
      "Went in for happy hour, great list of wines. 1[1]\n",
      "The servers are not pleasant to deal with and they don't always honor Pizza Hut coupons. 0[0]\n",
      "What a great double cheeseburger! 1[1]\n",
      "Cute, quaint, simple, honest. 1[1]\n",
      "Best tater tots in the southwest. 1[1]\n",
      "Their monster chicken fried steak and eggs is my all time favorite. 1[1]\n",
      "I could care less... The interior is just beautiful. 1[1]\n",
      "After I pulled up my car I waited for another 15 minutes before being acknowledged. 0[0]\n",
      "The vanilla ice cream was creamy and smooth while the profiterole (choux) pastry was fresh enough. 1[1]\n",
      "I probably won't be coming back here. 0[0]\n",
      "After one bite, I was hooked. 1[1]\n",
      "\u001b[91m Kind of hard to mess up a steak but they did. Unfavorable Review, Favorable Prediction (FP) 0[1]\u001b[00m\n",
      "There is nothing authentic about this place. 0[0]\n",
      "Terrible service! 0[0]\n",
      "The shower area is outside so you can only rinse, not take a full shower, unless you don't mind being nude for everyone to see! 0[0]\n",
      "I ordered the Lemon raspberry ice cocktail which was also incredible. 1[1]\n",
      "Crust is not good. 0[0]\n",
      "The only good thing was our waiter, he was very helpful and kept the bloddy mary's coming. 1[1]\n",
      "Ample portions and good prices. 1[1]\n",
      "They dropped more than the ball. 0[0]\n",
      "All in all an excellent restaurant highlighted by great service, a unique menu, and a beautiful setting. 1[1]\n",
      "\u001b[91m I have been to very few places to eat that under no circumstances would I ever return to, and this tops the list. Unfavorable Review, Favorable Prediction (FP) 0[1]\u001b[00m\n",
      "I love this place. 1[1]\n",
      "False Positives:  3  False Negatives:  2\n"
     ]
    }
   ],
   "source": [
    "def prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk))\n",
    "def prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk))\n",
    "\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for review, liked in zip(X_test,y_test):\n",
    "    tokenized = tokenizer.encode(review, add_special_tokens=True)\n",
    "    padded = np.array([tokenized + [0]*(max_len-len(tokenized))])\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    input_ids = torch.tensor(padded)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    feature = last_hidden_states[0][:,0,:].numpy()\n",
    "    \n",
    "    result = lr_clf.predict(feature)\n",
    "    if ((liked == 1) & (result == 0)):\n",
    "        prGreen(str(review) + \" Favorable Review, Unfavorable Prediction (FN) \"+str(liked) + str(result))\n",
    "        fn += 1\n",
    "    elif ((liked == 0) & (result == 1)):\n",
    "        prRed(str(review) + \" Unfavorable Review, Favorable Prediction (FP) \"+str(liked) + str(result))\n",
    "        fp += 1\n",
    "    else: print(str(review) + \" \"+str(liked) + str(result))\n",
    "\n",
    "print(\"False Positives: \", fp, \" False Negatives: \", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb1367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
